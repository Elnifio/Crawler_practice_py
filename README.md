*中文版本*
# Crawler_practice_python
用Python爬取COMP455 website的所有文件
***
作为Python爬虫的练手项目。

下载下来后直接运行main.py就可以开始抓取。

如果不想执行的话也可以直接拿data里面的所有文件，都是直接拉下来的。

Separate_steps文件夹内部的所有代码运行内容和main.py内容相同。

有时间会更新项目解析

### 需要用到的modules:
1. requests
2. os
3. re

***

*English Ver*
# Crawler_practice_python
Using Python to download all files from COMP 455 website
***
This project is served as a practice for intro to Python crawler.

Running main.py after pulling this repo would start downloading data.

If you do not wish to download all files by yourself, you could just open './data/' folder to access all pre-downloaded files.

All codes in './Separate_steps' serves the same purpose as main.py

Might update a detailed analysis of this project if possible.

***
### Required modules
1. requests
2. os
3. re

***
